name: "Agent Evaluation on Pull Request (Official Action)"

on:
  pull_request:
    branches:
      - main
    paths:
      - 'agent-setup/**'
      - 'data/agent-eval-data.json'
      - '.github/workflows/agent-eval-on-pr-official.yml'
  
  workflow_dispatch:
    inputs:
      agent_ids:
        description: 'Comma-separated agent IDs to evaluate'
        required: false
        type: string

permissions:
  id-token: write
  contents: read
  pull-requests: write

jobs:
  run-agent-evaluation:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout PR Branch
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history to access main branch
      
      - name: Azure Login using Federated Credentials
        uses: azure/login@v2
        with:
          client-id: ${{ vars.AZURE_CLIENT_ID }}
          tenant-id: ${{ vars.AZURE_TENANT_ID }}
          subscription-id: ${{ vars.AZURE_SUBSCRIPTION_ID }}
      
      - name: Check for Baseline Results
        id: check-baseline
        run: |
          # Check if baseline results exist on main branch
          git fetch origin main
          
          # Check if baseline file exists
          if git show origin/main:evaluation_results/baseline/baseline_metrics.json > /dev/null 2>&1; then
            echo "baseline_exists=true" >> $GITHUB_OUTPUT
            echo "üìä Baseline found on main branch"
            
            # Extract baseline to temp location
            git show origin/main:evaluation_results/baseline/baseline_metrics.json > /tmp/baseline_metrics.json
          else
            echo "baseline_exists=false" >> $GITHUB_OUTPUT
            echo "üìù No baseline found - this will be the first run"
          fi
      
      - name: Set Agent IDs
        id: set-agents
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ] && [ -n "${{ github.event.inputs.agent_ids }}" ]; then
            echo "agent_ids=${{ github.event.inputs.agent_ids }}" >> $GITHUB_OUTPUT
          else
            # Use baseline agent ID from variables
            echo "agent_ids=${{ vars.AGENT_ID_BASELINE }}" >> $GITHUB_OUTPUT
          fi
          
          echo "ü§ñ Agent IDs to evaluate: $(cat $GITHUB_OUTPUT | grep agent_ids | cut -d'=' -f2)"
      
      - name: Display Configuration
        run: |
          echo "üîç Evaluation Configuration:"
          echo "   Agent IDs: ${{ steps.set-agents.outputs.agent_ids }}"
          echo "   Project Endpoint: ${{ vars.AZURE_AI_PROJECT_ENDPOINT }}"
          echo "   Deployment: ${{ vars.AZURE_DEPLOYMENT_NAME }}"
          echo "   Data Path: ${{ github.workspace }}/data/agent-eval-data.json"
          echo "   API Version: ${{ vars.API_VERSION }}"
          echo "   Baseline exists: ${{ steps.check-baseline.outputs.baseline_exists }}"
      
      - name: Run AI Agent Evaluation
        id: run-evaluation
        uses: microsoft/ai-agent-evals@v2-beta
        with:
          azure-ai-project-endpoint: ${{ vars.AZURE_AI_PROJECT_ENDPOINT }}
          deployment-name: ${{ vars.AZURE_DEPLOYMENT_NAME }}
          agent-ids: ${{ steps.set-agents.outputs.agent_ids }}
          data-path: ${{ github.workspace }}/data/agent-eval-data.json
          evaluation-result-view: 'all-scores'
          api-version: ${{ vars.API_VERSION }}
      
      - name: Parse Evaluation Results
        id: parse-results
        run: |
          # The microsoft/ai-agent-evals action outputs results to GitHub Actions summary
          # We'll capture key metrics for our comparison logic
          
          # Create placeholder for parsed results
          # Note: The official action outputs to summary, so we'll need to adapt
          # our comparison logic or use the action's built-in comparison when using multiple agents
          
          echo "‚úÖ Evaluation completed using official Azure AI action"
          echo "üìä Results available in Actions summary above"
          
          # For baseline comparison, we'll need to either:
          # 1. Use the action's built-in multi-agent comparison feature
          # 2. Extract results from the action's output for custom comparison
          
          if [ "${{ steps.check-baseline.outputs.baseline_exists }}" == "true" ]; then
            echo "üìä Baseline exists for comparison"
            echo "‚ÑπÔ∏è For detailed comparison, consider using multiple agent IDs"
            echo "   with baseline agent as first ID (baseline-agent-id parameter)"
          fi
      
      - name: Generate PR Comment (Basic)
        if: always()
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            
            // Build basic comment
            let comment = "## ü§ñ Agent Evaluation Results\n\n";
            
            if ("${{ steps.run-evaluation.outcome }}" === "success") {
              comment += "### ‚úÖ Evaluation Completed\n\n";
              comment += "The evaluation has completed successfully using the official Azure AI action.\n\n";
              comment += "**View detailed results:**\n";
              comment += `- [GitHub Actions Summary](${context.payload.pull_request.html_url}/checks)\n`;
              comment += `- [Azure AI Foundry Portal](${process.env.AZURE_AI_PROJECT_ENDPOINT?.replace('/api/projects/', '/projects/')})\n\n`;
            } else {
              comment += "### ‚ùå Evaluation Failed\n\n";
              comment += "The evaluation encountered an error. Please check the workflow logs.\n\n";
            }
            
            comment += "### üìä Configuration\n\n";
            comment += `- **Agent IDs:** \`${{ steps.set-agents.outputs.agent_ids }}\`\n`;
            comment += `- **Deployment:** \`${{ vars.AZURE_DEPLOYMENT_NAME }}\`\n`;
            comment += `- **Test Queries:** 10\n`;
            
            if ("${{ steps.check-baseline.outputs.baseline_exists }}" === "true") {
              comment += "\n### üìà Baseline Comparison\n\n";
              comment += "A baseline exists. For detailed statistical comparison:\n";
              comment += "1. Include both baseline and variant agent IDs in the evaluation\n";
              comment += "2. The official action will automatically perform statistical comparison\n";
              comment += "3. Results appear in the GitHub Actions summary\n";
            } else {
              comment += "\n### üìù First Evaluation Run\n\n";
              comment += "This is the first evaluation run. Results will be saved as baseline when merged to main.\n";
            }
            
            comment += "\n---\n";
            comment += `**Run ID:** \`pr-${context.issue.number}-${Date.now()}\`\n`;
            comment += `**Workflow:** [View logs](${context.payload.repository.html_url}/actions/runs/${context.runId})\n`;
            
            // Find and update or create comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('ü§ñ Agent Evaluation Results')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }
      
      - name: Evaluation Summary
        if: success()
        run: |
          echo "‚úÖ Agent evaluation completed successfully!"
          echo ""
          echo "üìä Results have been posted to:"
          echo "   1. GitHub Actions Summary (see above)"
          echo "   2. PR Comment"
          echo "   3. Azure AI Foundry Portal"
          echo ""
          if [ "${{ steps.check-baseline.outputs.baseline_exists }}" == "true" ]; then
            echo "‚ÑπÔ∏è For statistical comparison with baseline:"
            echo "   Pass multiple agent IDs (baseline,variant) to the evaluation"
          else
            echo "üìù First evaluation run - will become baseline when merged"
          fi
