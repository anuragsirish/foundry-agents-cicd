name: üõ°Ô∏è Agent Safety Evaluation on PR (DISABLED - Merged into agent-evaluation-unified.yml)

on:
  workflow_dispatch:
  # pull_request:
  #   types: [opened, synchronize, reopened]
  #   paths:
  #     - 'agent-setup/**'
  #     - 'data/**'
  #     - 'scripts/**'
  #     - '.github/workflows/agent-safety-eval-on-pr.yml'

permissions:
  id-token: write
  contents: read
  pull-requests: write

jobs:
  safety-evaluation:
    name: üõ°Ô∏è Safety Evaluation
    runs-on: ubuntu-latest
    
    steps:
      - name: ü§ñ Checkout Repository
        uses: actions/checkout@v4
      
      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: üì¶ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: üîê Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ vars.AZURE_CLIENT_ID }}
          tenant-id: ${{ vars.AZURE_TENANT_ID }}
          subscription-id: ${{ vars.AZURE_SUBSCRIPTION_ID }}
      
      - name: üõ°Ô∏è Evaluate Baseline Agent (Safety)
        env:
          AZURE_CLIENT_ID: ${{ vars.AZURE_CLIENT_ID }}
          AZURE_TENANT_ID: ${{ vars.AZURE_TENANT_ID }}
          AZURE_SUBSCRIPTION_ID: ${{ vars.AZURE_SUBSCRIPTION_ID }}
          AZURE_AI_PROJECT_ENDPOINT: ${{ vars.AZURE_AI_PROJECT_ENDPOINT }}
          AZURE_DEPLOYMENT_NAME: ${{ vars.AZURE_DEPLOYMENT_NAME }}
          AGENT_ID_BASELINE: ${{ vars.AGENT_ID_BASELINE }}
        run: |
          echo "üõ°Ô∏è Running safety evaluation on Baseline Agent..."
          python scripts/local_safety_eval.py
      
      - name: üì§ Upload Baseline Safety Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: baseline-safety-results
          path: evaluation_results/safety_eval_output/
      
      - name: üõ°Ô∏è Evaluate V2 Agent (Safety)
        env:
          AZURE_CLIENT_ID: ${{ vars.AZURE_CLIENT_ID }}
          AZURE_TENANT_ID: ${{ vars.AZURE_TENANT_ID }}
          AZURE_SUBSCRIPTION_ID: ${{ vars.AZURE_SUBSCRIPTION_ID }}
          AZURE_AI_PROJECT_ENDPOINT: ${{ vars.AZURE_AI_PROJECT_ENDPOINT }}
          AZURE_DEPLOYMENT_NAME: ${{ vars.AZURE_DEPLOYMENT_NAME }}
          AGENT_ID_BASELINE: ${{ vars.AGENT_ID_V2 }}
        run: |
          echo "üõ°Ô∏è Running safety evaluation on V2 Agent..."
          # Clean previous results
          rm -rf evaluation_results/safety_eval_output/*
          python scripts/local_safety_eval.py
      
      - name: üì§ Upload V2 Safety Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: v2-safety-results
          path: evaluation_results/safety_eval_output/
      
      - name: üìä Compare Safety Results
        id: compare
        run: |
          python - <<'EOF'
          import json
          import os
          
          # Load baseline results
          try:
              with open('evaluation_results/safety_eval_output/safety-summary.json', 'r') as f:
                  v2_summary = json.load(f)
          except FileNotFoundError:
              print("‚ö†Ô∏è V2 summary not found")
              v2_summary = {}
          
          # Download baseline artifact (will be from previous step's artifact)
          # For now, we'll use the V2 as reference
          
          print("\n" + "="*80)
          print("üõ°Ô∏è SAFETY EVALUATION COMPARISON")
          print("="*80 + "\n")
          
          # Create comparison table
          comparison_md = """
          ## üõ°Ô∏è Safety Evaluation Results
          
          | Safety Category | Status | Notes |
          |----------------|--------|-------|
          """
          
          if v2_summary and 'safety_metrics' in v2_summary:
              for category, metrics in v2_summary['safety_metrics'].items():
                  defect_rate = metrics.get('defect_rate', 0)
                  status = metrics.get('status', 'üü° Unknown')
                  defect_pct = defect_rate * 100
                  
                  comparison_md += f"| {category.replace('_', ' ').title()} | {status} | {defect_pct:.1f}% defect rate |\n"
                  print(f"{category.replace('_', ' ').title():<25} {status:<15} ({defect_pct:.1f}% defect rate)")
          else:
              comparison_md += "| N/A | ‚ö†Ô∏è Warning | Safety evaluation did not complete |\n"
              print("‚ö†Ô∏è No safety metrics available")
          
          print("\n" + "="*80 + "\n")
          
          # Save comparison for PR comment
          with open('safety-comparison.md', 'w') as f:
              f.write(comparison_md)
          
          print("üìã Safety comparison saved for PR comment")
          EOF
      
      - name: üí¨ Comment Safety Results on PR
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let comparisonMd = '';
            try {
              comparisonMd = fs.readFileSync('safety-comparison.md', 'utf8');
            } catch (error) {
              comparisonMd = '## üõ°Ô∏è Safety Evaluation\n\n‚ö†Ô∏è Safety evaluation did not complete successfully.';
            }
            
            const comment = `${comparisonMd}
            
            ### üì¶ Artifacts
            - **Baseline Safety Results**: Available in workflow artifacts
            - **V2 Safety Results**: Available in workflow artifacts
            
            ---
            *Safety evaluations check for: Violence, Sexual content, Self-harm, Hate/Unfairness, Indirect attacks, and Protected material.*
            `;
            
            // Find existing safety comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const existingComment = comments.find(c => 
              c.body.includes('üõ°Ô∏è Safety Evaluation')
            );
            
            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }
      
      - name: üìã Post Safety Results to GitHub Actions Summary
        if: always()
        run: |
          if [ -f safety-comparison.md ]; then
            cat safety-comparison.md >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üì¶ Download Detailed Results" >> $GITHUB_STEP_SUMMARY
            echo "- Baseline Safety Results artifact" >> $GITHUB_STEP_SUMMARY
            echo "- V2 Safety Results artifact" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è Safety comparison not available" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: ‚úÖ Safety Evaluation Complete
        if: always()
        run: |
          echo "‚úÖ Safety evaluation workflow completed!"
          echo ""
          echo "‚ÑπÔ∏è  Note: This workflow provides safety insights but does not block PRs."
          echo "   Review the safety metrics and make an informed decision about merging."
