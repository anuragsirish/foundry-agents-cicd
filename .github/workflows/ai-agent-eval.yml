name: "AI Agent Evaluation"

on:
  workflow_dispatch:
    inputs:
      agent_ids:
        description: 'Comma-separated list of agent IDs to evaluate (first is baseline)'
        required: true
        type: string
      evaluation_view:
        description: 'Evaluation result view format'
        required: false
        type: choice
        default: 'default'
        options:
          - default
          - all-scores
          - raw-scores-only
  push:
    branches:
      - main
    paths:
      - 'data/agent-eval-data.json'
      - '.github/workflows/ai-agent-eval.yml'

permissions:
  id-token: write
  contents: read

jobs:
  run-agent-evaluation:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Azure Login using Federated Credentials
        uses: azure/login@v2
        with:
          client-id: ${{ vars.AZURE_CLIENT_ID }}
          tenant-id: ${{ vars.AZURE_TENANT_ID }}
          subscription-id: ${{ vars.AZURE_SUBSCRIPTION_ID }}

      - name: Set Agent IDs
        id: set-agents
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "agent_ids=${{ github.event.inputs.agent_ids }}" >> $GITHUB_OUTPUT
            echo "eval_view=${{ github.event.inputs.evaluation_view }}" >> $GITHUB_OUTPUT
          else
            # For push events, use environment variables or default values
            # You can configure these in GitHub repository settings
            echo "agent_ids=${{ vars.AGENT_ID_BASELINE }}" >> $GITHUB_OUTPUT
            echo "eval_view=default" >> $GITHUB_OUTPUT
          fi

      - name: Display Evaluation Configuration
        run: |
          echo "üîç Evaluation Configuration:"
          echo "   Agent IDs: ${{ steps.set-agents.outputs.agent_ids }}"
          echo "   Evaluation View: ${{ steps.set-agents.outputs.eval_view }}"
          echo "   Data Path: ${{ github.workspace }}/data/agent-eval-data.json"
          echo "   Deployment: ${{ vars.AZURE_DEPLOYMENT_NAME }}"

      - name: Run AI Agent Evaluation
        uses: microsoft/ai-agent-evals@v2-beta
        with:
          azure-ai-project-endpoint: ${{ vars.AZURE_AI_PROJECT_ENDPOINT }}
          deployment-name: ${{ vars.AZURE_DEPLOYMENT_NAME }}
          agent-ids: ${{ steps.set-agents.outputs.agent_ids }}
          data-path: ${{ github.workspace }}/data/agent-eval-data.json
          evaluation-result-view: ${{ steps.set-agents.outputs.eval_view }}
          api-version: ${{ vars.API_VERSION }}

      - name: Evaluation Complete
        if: success()
        run: |
          echo "‚úÖ Evaluation completed successfully!"
          echo "üìä View results in the Actions summary above"
          echo "üîó Detailed results available in Azure AI Foundry portal"

      - name: Evaluation Failed
        if: failure()
        run: |
          echo "‚ùå Evaluation failed!"
          echo "Please check the logs above for error details"
          echo "Common issues:"
          echo "  - Invalid agent IDs"
          echo "  - Incorrect Azure credentials"
          echo "  - Invalid data format"
          echo "  - Deployment not found"
