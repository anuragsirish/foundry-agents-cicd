# CI/CD Pipeline Architecture

## High-Level Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DEVELOPER WORKFLOW                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Developer                 GitHub                    Azure AI
        â”‚                        â”‚                          â”‚
        â”‚  1. Create PR          â”‚                          â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                          â”‚
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚  2. Trigger Workflow     â”‚
        â”‚                        â”‚     (agent-eval-on-pr)   â”‚
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚  3. Checkout code        â”‚
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚  4. Check for baseline   â”‚
        â”‚                        â”‚     (on main branch)     â”‚
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚  5. Run evaluation       â”‚
        â”‚                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚                          â”‚  6. Execute agent
        â”‚                        â”‚                          â”‚     with test queries
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚  7. Return results       â”‚
        â”‚                        â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚  8. Compare with         â”‚
        â”‚                        â”‚     baseline             â”‚
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚  9. Generate PR comment  â”‚
        â”‚                        â”‚                          â”‚
        â”‚  10. View results      â”‚                          â”‚
        â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                          â”‚
        â”‚     (PR comment)       â”‚                          â”‚
        â”‚                        â”‚                          â”‚
        â”‚  11. Quality gate      â”‚                          â”‚
        â”‚      âœ… PASS / âŒ FAIL â”‚                          â”‚
        â”‚                        â”‚                          â”‚
        â”‚  12. Merge PR          â”‚                          â”‚
        â”‚     (if approved)      â”‚                          â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                          â”‚
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚  13. Trigger baseline    â”‚
        â”‚                        â”‚      update workflow     â”‚
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚  14. Run eval on main    â”‚
        â”‚                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                        â”‚                          â”‚
        â”‚                        â”‚  15. Save new baseline   â”‚
        â”‚                        â”‚      to repository       â”‚
        â”‚                        â”‚                          â”‚
        â–¼                        â–¼                          â–¼


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BASELINE INITIALIZATION                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ First Run        â”‚
â”‚ (No baseline)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€> PR Workflow runs
         â”‚   â””â”€> Detects: baseline_exists=false
         â”‚       â””â”€> Shows "First evaluation run" message
         â”‚
         â”œâ”€> PR merged to main
         â”‚   â””â”€> update-baseline.yml triggers
         â”‚       â””â”€> Runs evaluation
         â”‚           â””â”€> Creates baseline_metrics.json
         â”‚               â””â”€> Commits to repository
         â”‚
         â””â”€> Future PRs
             â””â”€> Compare against baseline


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUALITY GATE DECISION TREE                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    Run Evaluation
                          â”‚
                          â–¼
                 Calculate Metrics
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Compare with Baselineâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â–¼                 â–¼                 â–¼
                   ğŸŸ¢ Improved        ğŸŸ¡ Stable        ğŸ”´ Degraded
                   (> +5%)            (Â±5%)            (> -5%)
                         â”‚                 â”‚                 â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ Quality Metrics: â”‚
                        â”‚ â€¢ Relevance      â”‚
                        â”‚ â€¢ Coherence      â”‚
                        â”‚ â€¢ Fluency        â”‚
                        â”‚ â€¢ Groundedness   â”‚
                        â”‚ â€¢ Tool Accuracy  â”‚
                        â”‚ â€¢ Intent Res.    â”‚
                        â”‚ â€¢ Task Adherence â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                                 â–¼
        âœ… ALL metrics                    âŒ ANY metric
        within threshold                  degraded >5%
                â”‚                                 â”‚
                â–¼                                 â–¼
        Quality Gate PASS              Quality Gate FAIL
                â”‚                                 â”‚
                â–¼                                 â–¼
        PR can be merged              Workflow exits with error
        (after review)                PR blocked


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FILE STRUCTURE & FLOW                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Repository Root
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ agent-eval-on-pr.yml â”€â”€â”
â”‚   â”‚   â”‚                       â”‚
â”‚   â”‚   â”œâ”€> Triggers on PR      â”‚
â”‚   â”‚   â”œâ”€> Fetches baseline â”€â”€â”€â”¼â”€> evaluation_results/baseline/
â”‚   â”‚   â”œâ”€> Runs evaluation     â”‚       baseline_metrics.json
â”‚   â”‚   â”œâ”€> Compares metrics    â”‚       (committed to repo)
â”‚   â”‚   â”œâ”€> Posts PR comment    â”‚
â”‚   â”‚   â””â”€> Quality gate check  â”‚
â”‚   â”‚                            â”‚
â”‚   â””â”€â”€ update-baseline.yml â”€â”€â”€â”€â”¤
â”‚       â”‚                        â”‚
â”‚       â”œâ”€> Triggers on merge   â”‚
â”‚       â”œâ”€> Runs evaluation     â”‚
â”‚       â””â”€> Updates baseline â”€â”€â”€â”˜
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ local_agent_eval.py
â”‚   â”‚   â””â”€> Used by workflows and local testing
â”‚   â”‚
â”‚   â””â”€â”€ initialize_baseline.py
â”‚       â””â”€> One-time setup
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ agent-eval-data.json
â”‚       â””â”€> Test queries (10 samples)
â”‚
â”œâ”€â”€ evaluation_results/
â”‚   â”œâ”€â”€ baseline/
â”‚   â”‚   â”œâ”€â”€ baseline_metrics.json      âœ… Committed
â”‚   â”‚   â””â”€â”€ baseline_full_results.json âœ… Committed
â”‚   â”‚
â”‚   â”œâ”€â”€ pr_runs/                        âŒ Not committed
â”‚   â”‚   â””â”€â”€ pr-{N}-{timestamp}/         (uploaded as artifacts)
â”‚   â”‚
â”‚   â””â”€â”€ agent_eval_output/              âŒ Not committed
â”‚       â””â”€â”€ evaluation_results.json     (local runs only)
â”‚
â””â”€â”€ .env
    â””â”€> Local development only


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA FLOW DETAILS                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input                 Processing              Output
â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€

Test Queries          Agent Execution         Conversation Logs
(data/agent-          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>          (messages array)
eval-data.json)              â”‚
                             â”‚
                             â–¼
                      
                      Evaluator Models        Quality Scores
                      (GPT-4o judges)   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  (0-5 scale)
                             â”‚
                             â”‚
                             â–¼
                      
                      Aggregate Metrics       Average Scores
                      (mean calculation) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  per metric
                             â”‚
                             â”‚
                             â–¼
                      
Current PR            Baseline Comparison     Comparison Results
Results          <â”€â”€> Baseline Metrics  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  (diff & %)
                             â”‚
                             â”‚
                             â–¼
                      
                      Quality Gate Logic      Pass/Fail Decision
                      (check thresholds) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  + PR comment


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      METRIC COMPARISON LOGIC                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

For each metric:

    current_value = 4.85
    baseline_value = 4.75
    
    diff = current - baseline
         = 4.85 - 4.75
         = +0.10
    
    diff_pct = (diff / baseline) Ã— 100
             = (0.10 / 4.75) Ã— 100
             = +2.1%
    
    if diff_pct < -5%:     # Degraded more than 5%
        âŒ FAIL
        emoji = ğŸ”´
    elif diff_pct > +5%:   # Improved more than 5%
        âœ… PASS
        emoji = ğŸŸ¢
    else:                  # Within Â±5%
        âœ… PASS
        emoji = ğŸŸ¡


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIMELINE: TYPICAL PR LIFECYCLE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

T+0:00    Developer creates PR
          â”‚
T+0:05    GitHub triggers workflow
          â”‚
T+0:30    Workflow starts
          â”œâ”€ Checkout code (10s)
          â”œâ”€ Setup Python (20s)
          â”œâ”€ Install deps (30s)
          â”œâ”€ Azure login (10s)
          â””â”€ Check baseline (5s)
          â”‚
T+1:45    Run evaluation
          â”œâ”€ Initialize client (10s)
          â”œâ”€ Execute 10 queries (60s)
          â”‚  â””â”€ ~6s per query
          â””â”€ Run evaluators (120s)
             â””â”€ 8 evaluators Ã— 10 queries
          â”‚
T+3:45    Compare & generate comment (15s)
          â”‚
T+4:00    Post PR comment
          â”‚
T+4:05    Quality gate check (5s)
          â”‚
          â””â”€> âœ… PASS or âŒ FAIL
          â”‚
[Manual]  Code review by team
          â”‚
[Manual]  PR approved & merged
          â”‚
T+0:00    Push to main triggers baseline update
          â”‚
T+4:00    New baseline saved and committed
          â”‚
          â””â”€> Ready for next PR


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SYSTEM COMPONENTS                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub Actions â”‚
â”‚                  â”‚
â”‚  Workflows:      â”‚
â”‚  â€¢ PR eval       â”‚
â”‚  â€¢ Baseline      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Uses
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Python Script  â”‚
â”‚                  â”‚
â”‚  local_agent_    â”‚
â”‚  eval.py         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Connects to
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Azure AI        â”‚       â”‚  Azure OpenAI    â”‚
â”‚  Project Client  â”‚       â”‚  (Evaluators)    â”‚
â”‚                  â”‚       â”‚                  â”‚
â”‚  â€¢ Agent         â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚  â€¢ GPT-4o        â”‚
â”‚  â€¢ Threads       â”‚       â”‚  â€¢ Judges        â”‚
â”‚  â€¢ Messages      â”‚       â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Produces
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Evaluation     â”‚
â”‚   Results        â”‚
â”‚                  â”‚
â”‚  â€¢ Metrics JSON  â”‚
â”‚  â€¢ Baseline      â”‚
â”‚  â€¢ Comparisons   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Points

1. **Automatic**: Triggers on every PR to main
2. **Smart**: Detects baseline existence
3. **Comprehensive**: 8+ quality metrics evaluated
4. **Transparent**: Results visible in PR comment
5. **Gated**: Blocks PRs if quality degrades >5%
6. **Self-updating**: Baseline updates on merge
7. **Historical**: Full git history of baselines
8. **Flexible**: Thresholds and metrics customizable

## Metrics Evaluated

| Category | Metrics |
|----------|---------|
| **Quality** (Block PRs) | Relevance, Coherence, Fluency, Groundedness, Tool Call Accuracy, Intent Resolution, Task Adherence, Similarity |
| **Performance** (Track only) | Response Time, Completion Tokens, Prompt Tokens |

## Next Steps

1. Review [CICD_PIPELINE.md](./CICD_PIPELINE.md) for setup
2. Configure GitHub variables
3. Initialize baseline
4. Create test PR
5. Monitor results
